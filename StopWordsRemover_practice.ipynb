{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StopWordsRemover_practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPovK6eIyRu1FYFvWlFRG+D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yp79i6gI_fp","executionInfo":{"status":"ok","timestamp":1637173489502,"user_tz":300,"elapsed":42183,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}},"outputId":"678cfee7-1327-44b8-8da7-9745195bb618"},"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.2.0'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.0 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [808 kB]\n","Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,442 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [666 kB]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,430 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,811 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,867 kB]\n","Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [928 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,222 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [699 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]\n","Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB]\n","Fetched 14.3 MB in 5s (2,674 kB/s)\n","Reading package lists... Done\n"]}]},{"cell_type":"code","metadata":{"id":"BfUobuD7JNlX","executionInfo":{"status":"ok","timestamp":1637173516320,"user_tz":300,"elapsed":10431,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}}},"source":[" # Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nea1oP4BJWmA","executionInfo":{"status":"ok","timestamp":1637173706365,"user_tz":300,"elapsed":7493,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}},"outputId":"a58f6db2-a482-4315-85ed-17e3ed82447c"},"source":["# Create DataFrame\n","sentenceData = spark.createDataFrame([\n","                                      (0, [\"Big\",\"data\",\"is\",\"super\",\"powerful\"]),\n","                                      (1, [\"This\",\"is\",\"going\",\"to\",\"be\",\"epic\"])\n","], [\"id\", \"raw\"])\n","sentenceData.show(truncate=False)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+\n","|id |raw                             |\n","+---+--------------------------------+\n","|0  |[Big, data, is, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |\n","+---+--------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"id":"a74ONVnvKGe_","executionInfo":{"status":"ok","timestamp":1637173734787,"user_tz":300,"elapsed":450,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}}},"source":["# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq5wqtBPKJKu","executionInfo":{"status":"ok","timestamp":1637173749438,"user_tz":300,"elapsed":313,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}}},"source":["# Run the Remover\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abERmAjnKOsD","executionInfo":{"status":"ok","timestamp":1637173839365,"user_tz":300,"elapsed":1895,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}},"outputId":"00a935dd-c4a6-4968-d6c1-f16c6908c8e2"},"source":["# Transform and show data\n","remover.transform(sentenceData).show(truncate=False)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ls1i9MUfK1ik","executionInfo":{"status":"ok","timestamp":1637174320234,"user_tz":300,"elapsed":538,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}},"outputId":"518bca58-69a9-42ac-8f3d-19ce933a76a1"},"source":["# example combining tokenizer and stopwordsRemover\n","from pyspark.ml.feature import Tokenizer\n","dataframe1 = spark.createDataFrame([\n","                                   (0,\"Spark is great\"),\n","                                   (1, \"We are learning Spark\"),\n","                                   (2, \"Spark is better than hadoop no doubt\")\n","], [\"id\", \"sentence\"])\n","dataframe1.show(truncate=False)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+\n","|id |sentence                            |\n","+---+------------------------------------+\n","|0  |Spark is great                      |\n","|1  |We are learning Spark               |\n","|2  |Spark is better than hadoop no doubt|\n","+---+------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUgaG1FkLSVO","executionInfo":{"status":"ok","timestamp":1637174387141,"user_tz":300,"elapsed":1207,"user":{"displayName":"Leidy Paola Dorado Muñoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvbdtS74FVQSjODpc7VwtyOb1G066qk8uZSBCxEg=s64","userId":"03939655928074764586"}},"outputId":"5addf8eb-d4c9-4a74-ebd9-1c3c15c94ec3"},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# Transform and Show DataFrame\n","tokenized_df = tokenizer.transform(dataframe1)\n","tokenized_df.show(truncate=False) \n","# Run the Remover\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n","# Transform and show data\n","remover.transform(tokenized_df).show(truncate=False)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |[spark, great]                |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |[learning, spark]             |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|[spark, better, hadoop, doubt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"]}]}]}